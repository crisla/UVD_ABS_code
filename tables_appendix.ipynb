{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from __future__ import division\n",
    "import numpy as np#\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intercala_listas(a, b):\n",
    "    c = list(zip(a, b))\n",
    "    return [elt for sublist in c for elt in sublist]\n",
    "\n",
    "def format_names(names):\n",
    "    names_latex = []\n",
    "    hi_there = 0\n",
    "    for n in names:\n",
    "        if n=='lsig_c':\n",
    "            hi_there+=1\n",
    "            if hi_there==2:\n",
    "                n += '2'\n",
    "        if n[-1]=='2':\n",
    "            n = n.replace('2','')\n",
    "#             n = n.replace('2','^x')\n",
    "        if n[0]=='s':\n",
    "            n = n.replace('sig',r'$\\hat{\\sigma}')\n",
    "            n += '$'\n",
    "        elif n[:2]=='ls':\n",
    "            n = n.replace('lsig',r'$\\hat{\\sigma}')\n",
    "            n += '$'\n",
    "#             n += ')$'\n",
    "        elif n[:2]=='ps':\n",
    "            n = ''\n",
    "#             n = n.replace('psig',r'$\\sigma')\n",
    "#             n += '$%'\n",
    "        elif n[:2]=='pl':\n",
    "            n = ''\n",
    "#             n = n.replace('plsig',r'$\\sigma')\n",
    "#             n += ')$%'\n",
    "        elif n==\"mu_y\":\n",
    "            n = n.replace('mu',r'$\\hat{\\mu}')\n",
    "            n += '$'\n",
    "        else:\n",
    "            n= \"\"\n",
    "#             n = n.replace('lpsig',r'$\\sigma')\n",
    "#             n += '^x)$%'\n",
    "    #     print n\n",
    "        names_latex.append(n)\n",
    "    return names_latex\n",
    "\n",
    "def format_short(AllTab):\n",
    "    tab_short = AllTab.iloc[-8:].copy()\n",
    "    tab_short.rename(index={'lsig_y2': 'log_variance', \n",
    "                                   'sig_x': 'spell_number',\n",
    "                                  'lsig_c': 'constant',\n",
    "                                   'lsig_e2': 'duration_dependence',\n",
    "                                   'lsig_b2': 'heterogeneity',\n",
    "                                   'lpsig_x': 'spell_number_percentage',\n",
    "                                  'lpsig_x': 'spell_number_percentage',\n",
    "                                  'lpsig_e': 'duration_dependence_percentage',\n",
    "                                  'lpsig_b': 'heterogeneity_percentage'},inplace='True')\n",
    "    tab_short = tab_short.append(pd.Series(1-AllTab.iloc[-3:].sum(),name='constant_percentage'))\n",
    "    tab_short = tab_short.reindex(['log_variance', 'spell_number', 'constant', 'duration_dependence',\n",
    "           'heterogeneity', 'constant_percentage','spell_number_percentage',\n",
    "           'duration_dependence_percentage', 'heterogeneity_percentage'])\n",
    "    return tab_short\n",
    "\n",
    "def format_very_short(AllTab):\n",
    "    tab_short = AllTab.iloc[-3:].copy()\n",
    "    tab_short = tab_short.T\n",
    "    tab_short.reset_index(level=0,inplace=True)\n",
    "    tab_short['shareC'] = 1-AllTab.iloc[-3:].sum().values\n",
    "    tab_short['var'] = AllTab.iloc[-8].values\n",
    "    tab_short['mean_days'] = AllTab.loc['mu_y'].values\n",
    "    tab_short.rename(columns={'lpsig_x': 'shareS',\n",
    "                            'lpsig_e': 'shareDD',\n",
    "                            'lpsig_b': 'shareH',\n",
    "                             'index':'cat'},inplace='True')\n",
    "    tab_short = tab_short[['shareC','shareDD','shareH','shareS','cat','var','mean_days']]\n",
    "    return tab_short\n",
    "\n",
    "def format_column_names(column_names):\n",
    "    var_name = []\n",
    "    type1 = []\n",
    "    for name in column_names:\n",
    "        split = name.split(',')\n",
    "        n,t = split[0],split[1:]\n",
    "        var_name.append(n)\n",
    "        type1.append(t)\n",
    "    return var_name,type1\n",
    "\n",
    "def read_results(inputfile):\n",
    "    table_raw = np.empty(23)\n",
    "    names = []\n",
    "    sigmas = []\n",
    "    column_names = []\n",
    "    noobs = []\n",
    "    results_follow = 0\n",
    "    first_row = 1\n",
    "    f = open(inputfile,'r')\n",
    "    for line in f:\n",
    "        words = line.split()\n",
    "#         print(words)\n",
    "        if len(words)>1 and words[1]==\"******\":\n",
    "            column_names.append(\"\".join(words[2:-1]))\n",
    "            results_follow=1\n",
    "        elif results_follow==1 and len(words)==7:\n",
    "            if first_row==1:\n",
    "                names.append(words[0])\n",
    "            sigmas.append(float(words[3]))\n",
    "            if words[0]=='lpsig_b':\n",
    "                results_follow=0\n",
    "                table_raw = np.vstack((table_raw,np.array(sigmas)))\n",
    "                noobs.append(int(words[2].replace(',',\"\")))\n",
    "                sigmas = []\n",
    "                first_row = 0\n",
    "    f.close()\n",
    "    return table_raw, names, column_names, noobs\n",
    "\n",
    "def read_descriptive_stats(inputfile):\n",
    "    table_raw = np.zeros((5,11,7))\n",
    "    var_names = []\n",
    "    row_n = 0\n",
    "    table_n = 0\n",
    "    column_names = []\n",
    "    results_follow = 0\n",
    "    names_done = 0\n",
    "    f = open(inputfile,'r')\n",
    "    for line in f:\n",
    "        words = line.split()\n",
    "        if len(words)>1 and words[0] == \"Variable\":\n",
    "            results_follow=1\n",
    "            if names_done == 0:\n",
    "                stats_names = words[2:]       \n",
    "        elif len(words)>1 and results_follow==1:\n",
    "            if words[0]!='before92':\n",
    "                if names_done ==0:\n",
    "                    column_names.append(words[0])\n",
    "                idx = 0\n",
    "                for w in words[2:]: \n",
    "                    w = w.replace(\",\",\"\")\n",
    "                    table_raw[idx,row_n,table_n] = np.array(w)\n",
    "                    idx+=1\n",
    "                row_n += 1\n",
    "\n",
    "            elif words[0]=='before92':\n",
    "                if names_done ==0:\n",
    "                    column_names.append(words[0])\n",
    "                    names_done = 1 \n",
    "                idx=0\n",
    "                for w in words[2:]: \n",
    "                    w = w.replace(\",\",\"\")\n",
    "                    table_raw[idx,row_n,table_n] = np.array(w)\n",
    "                    idx+=1\n",
    "                results_follow=0\n",
    "                table_n +=1\n",
    "                row_n = 0\n",
    "    f.close()\n",
    "    column_names_format =  ['duration','duration_last','age','female','college',\n",
    "                  'year_of_spell','last_T','last_P','last_A','before_84','before_92']\n",
    "    table_names_format = ['Raw', 'LTU', 'STU_noAjd', 'STU','STU_Recalls', 'NE_noAjd', 'NE']\n",
    "    means_table = pd.DataFrame(table_raw[1,:,:].T, columns=column_names_format) #, index=names_latex\n",
    "    means_table['version'] = table_names_format\n",
    "    stds_table = pd.DataFrame(table_raw[2,:,:].T, columns=column_names_format) #, index=names_latex\n",
    "    stds_table['version'] = table_names_format\n",
    "\n",
    "    final_table = pd.concat([means_table, stds_table]).sort_index(kind='merge')\n",
    "    final_table['stat'] = ['mean','std']*7\n",
    "    final_table = final_table[list(final_table.columns[-2:])+list(final_table.columns[:-2])]\n",
    "    \n",
    "    return final_table, means_table\n",
    "\n",
    "def read_descriptive_stats_T(inputfile):\n",
    "    table_raw = np.zeros((5,12,7))\n",
    "    var_names = []\n",
    "    row_n = 0\n",
    "    table_n = 0\n",
    "    column_names = []\n",
    "    results_follow = 0\n",
    "    names_done = 0\n",
    "    f = open(inputfile,'r')\n",
    "    for line in f:\n",
    "        words = line.split()\n",
    "        if len(words)>1 and words[0] == \"Variable\":\n",
    "            results_follow=1\n",
    "            if names_done == 0:\n",
    "                stats_names = words[2:]       \n",
    "        elif len(words)>1 and results_follow==1:\n",
    "            if words[0]!='before92':\n",
    "                if names_done ==0:\n",
    "                    column_names.append(words[0])\n",
    "                idx = 0\n",
    "                for w in words[2:]: \n",
    "                    w = w.replace(\",\",\"\")\n",
    "                    table_raw[idx,row_n,table_n] = np.array(w)\n",
    "                    idx+=1\n",
    "                row_n += 1\n",
    "\n",
    "            elif words[0]=='before92':\n",
    "                if names_done ==0:\n",
    "                    column_names.append(words[0])\n",
    "                    names_done = 1 \n",
    "                idx=0\n",
    "                for w in words[2:]: \n",
    "                    w = w.replace(\",\",\"\")\n",
    "                    table_raw[idx,row_n,table_n] = np.array(w)\n",
    "                    idx+=1\n",
    "                results_follow=0\n",
    "                table_n +=1\n",
    "                row_n = 0\n",
    "    f.close()\n",
    "#     print(table_raw[1,:,:].T)\n",
    "    column_names_format =  ['duration','duration_last','age','female','college',\n",
    "                  'year_of_spell','last_T','last_P','last_A','TempContracts','before_84','before_92']\n",
    "    table_names_format = ['Raw', 'LTU', 'STU_noAjd', 'STU','STU_Recalls', 'NE_noAjd', 'NE']\n",
    "    means_table = pd.DataFrame(table_raw[1,:,:].T, columns=column_names_format) #, index=names_latex\n",
    "    means_table['version'] = table_names_format\n",
    "    stds_table = pd.DataFrame(table_raw[2,:,:].T, columns=column_names_format) #, index=names_latex\n",
    "    stds_table['version'] = table_names_format\n",
    "\n",
    "    final_table = pd.concat([means_table, stds_table]).sort_index(kind='merge')\n",
    "    final_table['stat'] = ['mean','std']*7\n",
    "    final_table = final_table[list(final_table.columns[-2:])+list(final_table.columns[:-2])]\n",
    "    \n",
    "    return final_table, means_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "### New version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_short = \n",
    "    tab_short = tab_short.T\n",
    "    tab_short.reset_index(level=0,inplace=True)\n",
    "    tab_short['shareC'] = 1-AllTab.iloc[-3:].sum().values\n",
    "    tab_short['var'] = AllTab.iloc[-8].values\n",
    "    tab_short['mean_days'] = AllTab.loc['mu_y'].values\n",
    "    tab_short.rename(columns={'lpsig_x': 'shareS',\n",
    "                            'lpsig_e': 'shareDD',\n",
    "                            'lpsig_b': 'shareH',\n",
    "                             'index':'cat'},inplace='True')\n",
    "    tab_short = tab_short[['shareC','shareDD','shareH','shareS','cat','var','mean_days']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} &        Raw &         LTU &         STU &          NE \\\\\n",
      "\\midrule\n",
      "$\\hat{\\mu}_y$    &     190.76 &      253.93 &      226.00 &      182.17 \\\\\n",
      "$\\hat{\\sigma}_y$ &  66,216.70 &  137,446.50 &  171,335.50 &  142,494.00 \\\\\n",
      "$\\hat{\\sigma}_c$ &  43,338.46 &   82,829.80 &   71,756.18 &   49,024.22 \\\\\n",
      "                 &     (0.65) &      (0.60) &      (0.42) &      (0.34) \\\\\n",
      "$\\hat{\\sigma}_e$ &  15,928.33 &   36,268.23 &   78,898.72 &   77,632.69 \\\\\n",
      "                 &     (0.24) &      (0.26) &      (0.46) &      (0.54) \\\\\n",
      "$\\hat{\\sigma}_b$ &   6,949.91 &   18,348.45 &   20,680.60 &   15,837.13 \\\\\n",
      "                 &     (0.10) &      (0.13) &      (0.12) &      (0.11) \\\\\n",
      "$\\hat{\\sigma}_c$ &       1.64 &        1.64 &        1.64 &        1.64 \\\\\n",
      "                 &     (1.29) &      (1.12) &      (0.56) &      (0.49) \\\\\n",
      "$\\hat{\\sigma}_e$ &      -0.62 &       -0.51 &        0.77 &        0.90 \\\\\n",
      "                 &    (-0.51) &     (-0.36) &      (0.25) &      (0.26) \\\\\n",
      "$\\hat{\\sigma}_b$ &       0.25 &        0.33 &        0.52 &        0.78 \\\\\n",
      "                 &     (0.21) &      (0.23) &      (0.18) &      (0.24) \\\\\n",
      "N                &    430,272 &     391,578 &     667,060 &     869,048 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_raw, names, column_names, noobs = read_results('results/all_results96.log')\n",
    "names_latex = format_names(names)\n",
    "final_names = ['mu_y','sig_y','sig_c','psig_c','sig_e','psig_e','sig_b','psig_b',\n",
    "                     'lsig_c','plsig_c','lsig_e','lpsig_e','lsig_b','lpsig_b']\n",
    "parenthesis_names = ['psig_c','psig_e','psig_b','plsig_c','lpsig_e','lpsig_b']\n",
    "# table_raw_r, names_r, column_names_r, noobs_r = read_results('results/table_recalls.log')\n",
    "names[6] = 'lsig_co'\n",
    "AllTab = pd.DataFrame(table_raw[1:,:].T, index=names, columns=column_names)\n",
    "\n",
    "# rows\n",
    "AllTab = AllTab.T\n",
    "AllTab['plsig_c'] = AllTab['lsig_c']/AllTab['lsig_y2']\n",
    "AllTab = AllTab[final_names]\n",
    "\n",
    "AllTab['N'] = np.array(noobs)\n",
    "\n",
    "#columns\n",
    "AllTab = AllTab.T\n",
    "AllTab = AllTab[['Raw','LTU','STU+SpellAdj','NE+SpellAdj']]\n",
    "AllTab = AllTab.rename(columns={'STU+SpellAdj':'STU','NE+SpellAdj':\"NE\"})\n",
    "for name in final_names:\n",
    "    if name in parenthesis_names:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"({:,.2f})\".format(float(x)))\n",
    "    else:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"{:,.2f}\".format(float(x)))\n",
    "AllTab.loc['n'] = AllTab.loc['N'].apply(lambda x: \"{:,.0f}\".format(float(x)))\n",
    "\n",
    "AllTab = AllTab.rename(index=dict(zip(names,names_latex)))\n",
    "print(AllTab.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} &       Women &         Men &     College & Non-College \\\\\n",
      "\\midrule\n",
      "$\\hat{\\mu}_y$    &      284.70 &      178.19 &      197.69 &      230.83 \\\\\n",
      "$\\hat{\\sigma}_y$ &  248,107.00 &  103,720.50 &  126,073.70 &  179,093.10 \\\\\n",
      "$\\hat{\\sigma}_c$ &  105,323.20 &   44,418.57 &   52,585.83 &   75,164.22 \\\\\n",
      "                 &      (0.42) &      (0.43) &      (0.42) &      (0.42) \\\\\n",
      "$\\hat{\\sigma}_e$ &  118,512.80 &   46,636.29 &   59,982.81 &   82,045.23 \\\\\n",
      "                 &      (0.48) &      (0.45) &      (0.48) &      (0.46) \\\\\n",
      "$\\hat{\\sigma}_b$ &   24,270.96 &   12,665.60 &   13,505.06 &   21,883.65 \\\\\n",
      "                 &      (0.10) &      (0.12) &      (0.11) &      (0.12) \\\\\n",
      "$\\hat{\\sigma}_c$ &        1.64 &        1.64 &        1.64 &        1.64 \\\\\n",
      "                 &      (0.56) &      (0.58) &      (0.55) &      (0.56) \\\\\n",
      "$\\hat{\\sigma}_e$ &        0.88 &        0.69 &        0.88 &        0.74 \\\\\n",
      "                 &      (0.28) &      (0.24) &      (0.28) &      (0.24) \\\\\n",
      "$\\hat{\\sigma}_b$ &        0.44 &        0.49 &        0.46 &        0.53 \\\\\n",
      "                 &      (0.16) &      (0.18) &      (0.16) &      (0.19) \\\\\n",
      "N                &     299,416 &     367,644 &     119,076 &     567,114 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_raw_e, names, column_names_e, noobs_e = read_results('results/all_results_educ_96.log')\n",
    "table_raw_g, names, column_names_g, noobs_g = read_results('results/all_results_sex_96.log')\n",
    "names_latex = format_names(names)\n",
    "final_names = ['mu_y','sig_y','sig_c','psig_c','sig_e','psig_e','sig_b','psig_b',\n",
    "                     'lsig_c','plsig_c','lsig_e','lpsig_e','lsig_b','lpsig_b']\n",
    "parenthesis_names = ['psig_c','psig_e','psig_b','plsig_c','lpsig_e','lpsig_b']\n",
    "# table_raw_r, names_r, column_names_r, noobs_r = read_results('results/table_recalls.log')\n",
    "names[6] = 'lsig_co'\n",
    "AllTab = pd.DataFrame(table_raw_g[1:,:].T, index=names, columns=column_names_g)\n",
    "Tab_e = pd.DataFrame(table_raw_e[1:,:].T, index=names, columns=column_names_e)\n",
    "AllTab= pd.concat((AllTab,Tab_e),axis=1)\n",
    "\n",
    "# rows\n",
    "AllTab = AllTab.T\n",
    "AllTab['plsig_c'] = AllTab['lsig_c']/AllTab['lsig_y2']\n",
    "AllTab = AllTab[final_names]\n",
    "\n",
    "AllTab['N'] = np.array(np.hstack((noobs_g,noobs_e)))\n",
    "\n",
    "#columns\n",
    "AllTab = AllTab.T\n",
    "# \n",
    "AllTab = AllTab.rename(columns={'STU+SpellAdj,women':'Women','STU+SpellAdj,men':'Men',\n",
    "                               'STU+SpellAdj,college':'College','STU+SpellAdj,nocollege':'Non-College'})\n",
    "AllTab = AllTab[['Women','Men','College','Non-College']]\n",
    "for name in final_names:\n",
    "    if name in parenthesis_names:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"({:,.2f})\".format(float(x)))\n",
    "    else:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"{:,.2f}\".format(float(x)))\n",
    "AllTab.loc['N'] = AllTab.loc['N'].apply(lambda x: \"{:,.0f}\".format(float(x)))\n",
    "\n",
    "AllTab = AllTab.rename(index=dict(zip(names,names_latex)))\n",
    "print(AllTab.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "{} &  2002-2007 &  2008-2013 \\\\\n",
      "\\midrule\n",
      "$\\hat{\\mu}_y$    &     165.33 &     202.94 \\\\\n",
      "$\\hat{\\sigma}_y$ &  88,430.34 &  77,439.59 \\\\\n",
      "$\\hat{\\sigma}_c$ &  39,608.46 &  45,858.76 \\\\\n",
      "                 &     (0.45) &     (0.59) \\\\\n",
      "$\\hat{\\sigma}_e$ &  36,545.77 &  26,904.48 \\\\\n",
      "                 &     (0.41) &     (0.35) \\\\\n",
      "$\\hat{\\sigma}_b$ &  12,276.12 &   4,676.34 \\\\\n",
      "                 &     (0.14) &     (0.06) \\\\\n",
      "$\\hat{\\sigma}_c$ &       1.64 &       1.64 \\\\\n",
      "                 &     (0.60) &     (0.70) \\\\\n",
      "$\\hat{\\sigma}_e$ &       0.57 &       0.45 \\\\\n",
      "                 &     (0.18) &     (0.17) \\\\\n",
      "$\\hat{\\sigma}_b$ &       0.54 &       0.26 \\\\\n",
      "                 &     (0.21) &     (0.12) \\\\\n",
      "N                &    299,426 &    326,606 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_raw_bc, names, column_names_bc, noobs_bc = read_results('results/BC_all.log')\n",
    "names_latex = format_names(names)\n",
    "final_names = ['mu_y','sig_y','sig_c','psig_c','sig_e','psig_e','sig_b','psig_b',\n",
    "                     'lsig_c','plsig_c','lsig_e','lpsig_e','lsig_b','lpsig_b']\n",
    "parenthesis_names = ['psig_c','psig_e','psig_b','plsig_c','lpsig_e','lpsig_b']\n",
    "names[6] = 'lsig_co'\n",
    "AllTab = pd.DataFrame(table_raw_bc[1:,:].T, index=names, columns=column_names_bc)\n",
    "\n",
    "# rows\n",
    "AllTab = AllTab.T\n",
    "AllTab['plsig_c'] = AllTab['lsig_c']/AllTab['lsig_y2']\n",
    "AllTab = AllTab[final_names]\n",
    "\n",
    "AllTab['N'] = np.array(noobs_bc)\n",
    "\n",
    "#columns\n",
    "AllTab = AllTab.T\n",
    "# \n",
    "AllTab = AllTab.rename(columns={'STU+Spellcorrection,2002-2007':'2002-2007',\n",
    "                               'STU+Spellcorrection,2008-2013':'2008-2013'})\n",
    "\n",
    "for name in final_names:\n",
    "    if name in parenthesis_names:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"({:,.2f})\".format(float(x)))\n",
    "    else:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"{:,.2f}\".format(float(x)))\n",
    "AllTab.loc['N'] = AllTab.loc['N'].apply(lambda x: \"{:,.0f}\".format(float(x)))\n",
    "\n",
    "AllTab = AllTab.rename(index=dict(zip(names,names_latex)))\n",
    "print(AllTab.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} &  2002-2007 &  2008-2013 &  2002-2007 &  2008-2013 \\\\\n",
      "\\midrule\n",
      "$\\hat{\\mu}_y$    &     166.84 &     207.06 &     155.12 &     179.60 \\\\\n",
      "$\\hat{\\sigma}_y$ &  91,063.37 &  80,457.48 &  77,204.69 &  57,495.90 \\\\\n",
      "$\\hat{\\sigma}_c$ &  40,817.05 &  47,621.09 &  32,797.27 &  36,105.39 \\\\\n",
      "                 &     (0.45) &     (0.59) &     (0.42) &     (0.63) \\\\\n",
      "$\\hat{\\sigma}_e$ &  37,264.28 &  28,090.94 &  35,669.91 &  17,541.44 \\\\\n",
      "                 &     (0.41) &     (0.35) &     (0.46) &     (0.31) \\\\\n",
      "$\\hat{\\sigma}_b$ &  12,982.03 &   4,745.46 &   8,737.51 &   3,849.07 \\\\\n",
      "                 &     (0.14) &     (0.06) &     (0.11) &     (0.07) \\\\\n",
      "$\\hat{\\sigma}_c$ &       1.64 &       1.64 &       1.64 &       1.64 \\\\\n",
      "                 &     (0.60) &     (0.71) &     (0.58) &     (0.67) \\\\\n",
      "$\\hat{\\sigma}_e$ &       0.53 &       0.42 &       0.73 &       0.51 \\\\\n",
      "                 &     (0.17) &     (0.17) &     (0.23) &     (0.20) \\\\\n",
      "$\\hat{\\sigma}_b$ &       0.55 &       0.26 &       0.46 &       0.29 \\\\\n",
      "                 &     (0.22) &     (0.12) &     (0.18) &     (0.12) \\\\\n",
      "N                &    256,826 &    283,276 &     50,922 &     55,264 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_raw_bc, names, column_names_bc, noobs_bc = read_results('results/BC_educ.log')\n",
    "names_latex = format_names(names)\n",
    "final_names = ['mu_y','sig_y','sig_c','psig_c','sig_e','psig_e','sig_b','psig_b',\n",
    "                     'lsig_c','plsig_c','lsig_e','lpsig_e','lsig_b','lpsig_b']\n",
    "parenthesis_names = ['psig_c','psig_e','psig_b','plsig_c','lpsig_e','lpsig_b']\n",
    "names[6] = 'lsig_co'\n",
    "AllTab = pd.DataFrame(table_raw_bc[1:,:].T, index=names, columns=column_names_bc)\n",
    "\n",
    "# rows\n",
    "AllTab = AllTab.T\n",
    "AllTab['plsig_c'] = AllTab['lsig_c']/AllTab['lsig_y2']\n",
    "AllTab = AllTab[final_names]\n",
    "\n",
    "AllTab['N'] = np.array(noobs_bc)\n",
    "\n",
    "#columns\n",
    "AllTab = AllTab.T\n",
    "AllTab = AllTab[['STU+Spellcorrection,2002-2007,nocollege',\n",
    "               'STU+Spellcorrection,2008-2013,nocollege',\n",
    "               'STU+Spellcorrection,2002-2007,college',\n",
    "               'STU+Spellcorrection,2008-2013,college']]\n",
    "\n",
    "AllTab = AllTab.rename(columns={'STU+Spellcorrection,2002-2007,college':'2002-2007',\n",
    "                                'STU+Spellcorrection,2002-2007,nocollege':'2002-2007',\n",
    "                               'STU+Spellcorrection,2008-2013,college':'2008-2013',\n",
    "                                'STU+Spellcorrection,2008-2013,nocollege':'2008-2013'})\n",
    "\n",
    "for name in final_names:\n",
    "    if name in parenthesis_names:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"({:,.2f})\".format(float(x)))\n",
    "    else:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"{:,.2f}\".format(float(x)))\n",
    "AllTab.loc['N'] = AllTab.loc['N'].apply(lambda x: \"{:,.0f}\".format(float(x)))\n",
    "\n",
    "AllTab = AllTab.rename(index=dict(zip(names,names_latex)))\n",
    "print(AllTab.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
