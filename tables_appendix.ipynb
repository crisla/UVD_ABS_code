{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from __future__ import division\n",
    "import numpy as np#\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intercala_listas(a, b):\n",
    "    c = list(zip(a, b))\n",
    "    return [elt for sublist in c for elt in sublist]\n",
    "\n",
    "def format_names(names):\n",
    "    names_latex = []\n",
    "    hi_there = 0\n",
    "    for n in names:\n",
    "        if n=='lsig_c':\n",
    "            hi_there+=1\n",
    "            if hi_there==2:\n",
    "                n += '2'\n",
    "        if n[-1]=='2':\n",
    "            n = n.replace('2','')\n",
    "#             n = n.replace('2','^x')\n",
    "        if n[0]=='s':\n",
    "            n = n.replace('sig',r'$\\hat{\\sigma}')\n",
    "            n += '$'\n",
    "        elif n[:2]=='ls':\n",
    "            n = n.replace('lsig',r'$\\hat{\\sigma}')\n",
    "            n += '$'\n",
    "#             n += ')$'\n",
    "        elif n[:2]=='ps':\n",
    "            n = ''\n",
    "#             n = n.replace('psig',r'$\\sigma')\n",
    "#             n += '$%'\n",
    "        elif n[:2]=='pl':\n",
    "            n = ''\n",
    "#             n = n.replace('plsig',r'$\\sigma')\n",
    "#             n += ')$%'\n",
    "        elif n==\"mu_y\":\n",
    "            n = n.replace('mu',r'$\\hat{\\mu}')\n",
    "            n += '$'\n",
    "        else:\n",
    "            n= \"\"\n",
    "#             n = n.replace('lpsig',r'$\\sigma')\n",
    "#             n += '^x)$%'\n",
    "    #     print n\n",
    "        names_latex.append(n)\n",
    "    return names_latex\n",
    "\n",
    "def format_short(AllTab):\n",
    "    tab_short = AllTab.iloc[-8:].copy()\n",
    "    tab_short.rename(index={'lsig_y2': 'log_variance', \n",
    "                                   'sig_x': 'spell_number',\n",
    "                                  'lsig_c': 'constant',\n",
    "                                   'lsig_e2': 'duration_dependence',\n",
    "                                   'lsig_b2': 'heterogeneity',\n",
    "                                   'lpsig_x': 'spell_number_percentage',\n",
    "                                  'lpsig_x': 'spell_number_percentage',\n",
    "                                  'lpsig_e': 'duration_dependence_percentage',\n",
    "                                  'lpsig_b': 'heterogeneity_percentage'},inplace='True')\n",
    "    tab_short = tab_short.append(pd.Series(1-AllTab.iloc[-3:].sum(),name='constant_percentage'))\n",
    "    tab_short = tab_short.reindex(['log_variance', 'spell_number', 'constant', 'duration_dependence',\n",
    "           'heterogeneity', 'constant_percentage','spell_number_percentage',\n",
    "           'duration_dependence_percentage', 'heterogeneity_percentage'])\n",
    "    return tab_short\n",
    "\n",
    "def format_very_short(AllTab):\n",
    "    tab_short = AllTab.iloc[-3:].copy()\n",
    "    tab_short = tab_short.T\n",
    "    tab_short.reset_index(level=0,inplace=True)\n",
    "    tab_short['shareC'] = 1-AllTab.iloc[-3:].sum().values\n",
    "    tab_short['var'] = AllTab.iloc[-8].values\n",
    "    tab_short['mean_days'] = AllTab.loc['mu_y'].values\n",
    "    tab_short.rename(columns={'lpsig_x': 'shareS',\n",
    "                            'lpsig_e': 'shareDD',\n",
    "                            'lpsig_b': 'shareH',\n",
    "                             'index':'cat'},inplace='True')\n",
    "    tab_short = tab_short[['shareC','shareDD','shareH','shareS','cat','var','mean_days']]\n",
    "    return tab_short\n",
    "\n",
    "def format_column_names(column_names):\n",
    "    var_name = []\n",
    "    type1 = []\n",
    "    for name in column_names:\n",
    "        split = name.split(',')\n",
    "        n,t = split[0],split[1:]\n",
    "        var_name.append(n)\n",
    "        type1.append(t)\n",
    "    return var_name,type1\n",
    "\n",
    "def read_results(inputfile):\n",
    "    table_raw = np.empty(23)\n",
    "    names = []\n",
    "    sigmas = []\n",
    "    column_names = []\n",
    "    noobs = []\n",
    "    results_follow = 0\n",
    "    first_row = 1\n",
    "    f = open(inputfile,'r')\n",
    "    for line in f:\n",
    "        words = line.split()\n",
    "#         print(words)\n",
    "        if len(words)>1 and words[1]==\"******\":\n",
    "            column_names.append(\"\".join(words[2:-1]))\n",
    "            results_follow=1\n",
    "        elif results_follow==1 and len(words)==7:\n",
    "            if first_row==1:\n",
    "                names.append(words[0])\n",
    "            sigmas.append(float(words[3]))\n",
    "            if words[0]=='lpsig_b':\n",
    "                results_follow=0\n",
    "                table_raw = np.vstack((table_raw,np.array(sigmas)))\n",
    "                noobs.append(int(words[2].replace(',',\"\")))\n",
    "                sigmas = []\n",
    "                first_row = 0\n",
    "    f.close()\n",
    "    return table_raw, names, column_names, noobs\n",
    "\n",
    "def read_descriptive_stats(inputfile):\n",
    "    table_raw = np.zeros((5,11,7))\n",
    "    var_names = []\n",
    "    row_n = 0\n",
    "    table_n = 0\n",
    "    column_names = []\n",
    "    results_follow = 0\n",
    "    names_done = 0\n",
    "    f = open(inputfile,'r')\n",
    "    for line in f:\n",
    "        words = line.split()\n",
    "        if len(words)>1 and words[0] == \"Variable\":\n",
    "            results_follow=1\n",
    "            if names_done == 0:\n",
    "                stats_names = words[2:]       \n",
    "        elif len(words)>1 and results_follow==1:\n",
    "            if words[0]!='before92':\n",
    "                if names_done ==0:\n",
    "                    column_names.append(words[0])\n",
    "                idx = 0\n",
    "                for w in words[2:]: \n",
    "                    w = w.replace(\",\",\"\")\n",
    "                    table_raw[idx,row_n,table_n] = np.array(w)\n",
    "                    idx+=1\n",
    "                row_n += 1\n",
    "\n",
    "            elif words[0]=='before92':\n",
    "                if names_done ==0:\n",
    "                    column_names.append(words[0])\n",
    "                    names_done = 1 \n",
    "                idx=0\n",
    "                for w in words[2:]: \n",
    "                    w = w.replace(\",\",\"\")\n",
    "                    table_raw[idx,row_n,table_n] = np.array(w)\n",
    "                    idx+=1\n",
    "                results_follow=0\n",
    "                table_n +=1\n",
    "                row_n = 0\n",
    "    f.close()\n",
    "    column_names_format =  ['duration','duration_last','age','female','college',\n",
    "                  'year_of_spell','last_T','last_P','last_A','before_84','before_92']\n",
    "    table_names_format = ['Raw', 'LTU', 'STU_noAjd', 'STU','STU_Recalls', 'NE_noAjd', 'NE']\n",
    "    means_table = pd.DataFrame(table_raw[1,:,:].T, columns=column_names_format) #, index=names_latex\n",
    "    means_table['version'] = table_names_format\n",
    "    stds_table = pd.DataFrame(table_raw[2,:,:].T, columns=column_names_format) #, index=names_latex\n",
    "    stds_table['version'] = table_names_format\n",
    "\n",
    "    final_table = pd.concat([means_table, stds_table]).sort_index(kind='merge')\n",
    "    final_table['stat'] = ['mean','std']*7\n",
    "    final_table = final_table[list(final_table.columns[-2:])+list(final_table.columns[:-2])]\n",
    "    \n",
    "    return final_table, means_table\n",
    "\n",
    "def read_descriptive_stats_T(inputfile):\n",
    "    table_raw = np.zeros((5,12,7))\n",
    "    var_names = []\n",
    "    row_n = 0\n",
    "    table_n = 0\n",
    "    column_names = []\n",
    "    results_follow = 0\n",
    "    names_done = 0\n",
    "    f = open(inputfile,'r')\n",
    "    for line in f:\n",
    "        words = line.split()\n",
    "        if len(words)>1 and words[0] == \"Variable\":\n",
    "            results_follow=1\n",
    "            if names_done == 0:\n",
    "                stats_names = words[2:]       \n",
    "        elif len(words)>1 and results_follow==1:\n",
    "            if words[0]!='before92':\n",
    "                if names_done ==0:\n",
    "                    column_names.append(words[0])\n",
    "                idx = 0\n",
    "                for w in words[2:]: \n",
    "                    w = w.replace(\",\",\"\")\n",
    "                    table_raw[idx,row_n,table_n] = np.array(w)\n",
    "                    idx+=1\n",
    "                row_n += 1\n",
    "\n",
    "            elif words[0]=='before92':\n",
    "                if names_done ==0:\n",
    "                    column_names.append(words[0])\n",
    "                    names_done = 1 \n",
    "                idx=0\n",
    "                for w in words[2:]: \n",
    "                    w = w.replace(\",\",\"\")\n",
    "                    table_raw[idx,row_n,table_n] = np.array(w)\n",
    "                    idx+=1\n",
    "                results_follow=0\n",
    "                table_n +=1\n",
    "                row_n = 0\n",
    "    f.close()\n",
    "#     print(table_raw[1,:,:].T)\n",
    "    column_names_format =  ['duration','duration_last','age','female','college',\n",
    "                  'year_of_spell','last_T','last_P','last_A','TempContracts','before_84','before_92']\n",
    "    table_names_format = ['Raw', 'LTU', 'STU_noAjd', 'STU','STU_Recalls', 'NE_noAjd', 'NE']\n",
    "    means_table = pd.DataFrame(table_raw[1,:,:].T, columns=column_names_format) #, index=names_latex\n",
    "    means_table['version'] = table_names_format\n",
    "    stds_table = pd.DataFrame(table_raw[2,:,:].T, columns=column_names_format) #, index=names_latex\n",
    "    stds_table['version'] = table_names_format\n",
    "\n",
    "    final_table = pd.concat([means_table, stds_table]).sort_index(kind='merge')\n",
    "    final_table['stat'] = ['mean','std']*7\n",
    "    final_table = final_table[list(final_table.columns[-2:])+list(final_table.columns[:-2])]\n",
    "    \n",
    "    return final_table, means_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "### New version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} &        Raw &         LTU &         STU &          NE \\\\\n",
      "\\midrule\n",
      "$\\hat{\\mu}_y$    &     188.47 &      251.36 &      225.21 &      181.84 \\\\\n",
      "$\\hat{\\sigma}_y$ &  66,006.31 &  136,710.30 &  170,835.90 &  142,086.80 \\\\\n",
      "$\\hat{\\sigma}_c$ &  42,575.36 &   81,526.63 &   71,360.46 &   48,872.06 \\\\\n",
      "                 &     (0.65) &      (0.60) &      (0.42) &      (0.34) \\\\\n",
      "$\\hat{\\sigma}_e$ &  16,377.16 &   36,837.83 &   78,832.23 &   77,406.55 \\\\\n",
      "                 &     (0.25) &      (0.27) &      (0.46) &      (0.54) \\\\\n",
      "$\\hat{\\sigma}_b$ &   7,053.79 &   18,345.88 &   20,643.17 &   15,808.17 \\\\\n",
      "                 &     (0.11) &      (0.13) &      (0.12) &      (0.11) \\\\\n",
      "$\\hat{\\sigma}_c$ &       1.64 &        1.64 &        1.64 &        1.64 \\\\\n",
      "                 &     (1.23) &      (1.09) &      (0.56) &      (0.49) \\\\\n",
      "$\\hat{\\sigma}_e$ &      -0.60 &       -0.50 &        0.77 &        0.90 \\\\\n",
      "                 &    (-0.47) &     (-0.34) &      (0.25) &      (0.26) \\\\\n",
      "$\\hat{\\sigma}_b$ &       0.29 &        0.36 &        0.52 &        0.78 \\\\\n",
      "                 &     (0.23) &      (0.24) &      (0.18) &      (0.24) \\\\\n",
      "N                &     441650 &      400714 &      672456 &      873268 \\\\\n",
      "n                &    441,650 &     400,714 &     672,456 &     873,268 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_raw, names, column_names, noobs = read_results('results/all_results96.log')\n",
    "names_latex = format_names(names)\n",
    "final_names = ['mu_y','sig_y','sig_c','psig_c','sig_e','psig_e','sig_b','psig_b',\n",
    "                     'lsig_c','plsig_c','lsig_e','lpsig_e','lsig_b','lpsig_b']\n",
    "parenthesis_names = ['psig_c','psig_e','psig_b','plsig_c','lpsig_e','lpsig_b']\n",
    "# table_raw_r, names_r, column_names_r, noobs_r = read_results('results/table_recalls.log')\n",
    "names[6] = 'lsig_co'\n",
    "AllTab = pd.DataFrame(table_raw[1:,:].T, index=names, columns=column_names)\n",
    "\n",
    "# rows\n",
    "AllTab = AllTab.T\n",
    "AllTab['plsig_c'] = AllTab['lsig_c']/AllTab['lsig_y2']\n",
    "AllTab = AllTab[final_names]\n",
    "\n",
    "AllTab['N'] = np.array(noobs)\n",
    "\n",
    "#columns\n",
    "AllTab = AllTab.T\n",
    "AllTab = AllTab[['Raw','LTU','STU+SpellAdj','NE+SpellAdj']]\n",
    "AllTab = AllTab.rename(columns={'STU+SpellAdj':'STU','NE+SpellAdj':\"NE\"})\n",
    "for name in final_names:\n",
    "    if name in parenthesis_names:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"({:,.2f})\".format(float(x)))\n",
    "    else:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"{:,.2f}\".format(float(x)))\n",
    "AllTab.loc['n'] = AllTab.loc['N'].apply(lambda x: \"{:,.0f}\".format(float(x)))\n",
    "\n",
    "AllTab = AllTab.rename(index=dict(zip(names,names_latex)))\n",
    "print(AllTab.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "{} & Spell Control Only & All Controls \\\\\n",
      "\\midrule\n",
      "$\\hat{\\mu}_y$    &             225.21 &       216.37 \\\\\n",
      "$\\hat{\\sigma}_y$ &         170,835.90 &   156,735.80 \\\\\n",
      "$\\hat{\\sigma}_c$ &          71,360.46 &    65,056.94 \\\\\n",
      "                 &             (0.42) &       (0.42) \\\\\n",
      "$\\hat{\\sigma}_e$ &          78,832.23 &    73,436.09 \\\\\n",
      "                 &             (0.46) &       (0.47) \\\\\n",
      "$\\hat{\\sigma}_b$ &          20,643.17 &    18,242.80 \\\\\n",
      "                 &             (0.12) &       (0.12) \\\\\n",
      "$\\hat{\\sigma}_c$ &               1.64 &         1.64 \\\\\n",
      "                 &             (0.56) &       (0.57) \\\\\n",
      "$\\hat{\\sigma}_e$ &               0.77 &         0.74 \\\\\n",
      "                 &             (0.25) &       (0.23) \\\\\n",
      "$\\hat{\\sigma}_b$ &               0.52 &         0.48 \\\\\n",
      "                 &             (0.18) &       (0.15) \\\\\n",
      "n                &            672,456 &      648,704 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_raw, names, column_names, noobs = read_results('results/all_results96_x.log')\n",
    "table_raw_o, names_o, column_names_o, noobs_o = read_results('results/all_results96.log')\n",
    "names_latex = format_names(names)\n",
    "final_names = ['mu_y','sig_y','sig_c','psig_c','sig_e','psig_e','sig_b','psig_b',\n",
    "                     'lsig_c','plsig_c','lsig_e','lpsig_e','lsig_b','lpsig_b']\n",
    "parenthesis_names = ['psig_c','psig_e','psig_b','plsig_c','lpsig_e','lpsig_b']\n",
    "# table_raw_r, names_r, column_names_r, noobs_r = read_results('results/table_recalls.log')\n",
    "names[6] = 'lsig_co'\n",
    "AllTab = pd.DataFrame(table_raw[1:,:].T, index=names, columns=column_names)\n",
    "Tab_o = pd.DataFrame(table_raw_o[1:,:].T, index=names, columns=column_names_o)\n",
    "Tab_o = Tab_o[['STU+SpellAdj',]]\n",
    "Tab_o = Tab_o.rename(columns={'STU+SpellAdj':'Spell Control Only'})\n",
    "AllTab= pd.concat((Tab_o,AllTab),axis=1)\n",
    "\n",
    "# rows\n",
    "AllTab = AllTab.T\n",
    "AllTab['plsig_c'] = AllTab['lsig_c']/AllTab['lsig_y2']\n",
    "AllTab = AllTab[final_names]\n",
    "\n",
    "AllTab['n'] = np.array(np.hstack((noobs_o[-2],noobs)))\n",
    "\n",
    "#columns\n",
    "AllTab = AllTab.T\n",
    "# AllTab = AllTab[['Raw','LTU','STU+SpellAdj','NE+SpellAdj']]\n",
    "AllTab = AllTab.rename(columns={'STU+SpellAdj':'All Controls'})\n",
    "for name in final_names:\n",
    "    if name in parenthesis_names:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"({:,.2f})\".format(float(x)))\n",
    "    else:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"{:,.2f}\".format(float(x)))\n",
    "AllTab.loc['n'] = AllTab.loc['n'].apply(lambda x: \"{:,.0f}\".format(float(x)))\n",
    "\n",
    "AllTab = AllTab.rename(index=dict(zip(names,names_latex)))\n",
    "print(AllTab.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} &        Raw &         LTU &         STU &          NE \\\\\n",
      "\\midrule\n",
      "$\\hat{\\mu}_y$    &     192.29 &      257.45 &      273.38 &      246.66 \\\\\n",
      "$\\hat{\\sigma}_y$ &  69,483.74 &  143,092.10 &  179,458.40 &  162,236.50 \\\\\n",
      "$\\hat{\\sigma}_c$ &  43,731.52 &   84,157.50 &   95,527.38 &   78,002.34 \\\\\n",
      "                 &     (0.63) &      (0.59) &      (0.53) &      (0.48) \\\\\n",
      "$\\hat{\\sigma}_e$ &  18,997.38 &   41,058.52 &   63,138.81 &   67,073.44 \\\\\n",
      "                 &     (0.27) &      (0.29) &      (0.35) &      (0.41) \\\\\n",
      "$\\hat{\\sigma}_b$ &   6,754.85 &   17,876.11 &   20,792.24 &   17,160.70 \\\\\n",
      "                 &     (0.10) &      (0.12) &      (0.12) &      (0.11) \\\\\n",
      "$\\hat{\\sigma}_c$ &       1.64 &        1.64 &        1.64 &        1.64 \\\\\n",
      "                 &     (1.09) &      (1.01) &      (0.89) &      (0.74) \\\\\n",
      "$\\hat{\\sigma}_e$ &      -0.39 &       -0.34 &       -0.07 &        0.24 \\\\\n",
      "                 &    (-0.27) &     (-0.21) &     (-0.04) &      (0.11) \\\\\n",
      "$\\hat{\\sigma}_b$ &       0.26 &        0.32 &        0.27 &        0.33 \\\\\n",
      "                 &     (0.17) &      (0.20) &      (0.15) &      (0.15) \\\\\n",
      "N                &     335750 &      335750 &      462112 &      589474 \\\\\n",
      "n                &    335,750 &     335,750 &     462,112 &     589,474 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_raw, names, column_names, noobs = read_results('results/all_results96_30.log')\n",
    "names_latex = format_names(names)\n",
    "final_names = ['mu_y','sig_y','sig_c','psig_c','sig_e','psig_e','sig_b','psig_b',\n",
    "                     'lsig_c','plsig_c','lsig_e','lpsig_e','lsig_b','lpsig_b']\n",
    "parenthesis_names = ['psig_c','psig_e','psig_b','plsig_c','lpsig_e','lpsig_b']\n",
    "# table_raw_r, names_r, column_names_r, noobs_r = read_results('results/table_recalls.log')\n",
    "names[6] = 'lsig_co'\n",
    "AllTab = pd.DataFrame(table_raw_g[1:,:].T, index=names, columns=column_names_g)\n",
    "\n",
    "# rows\n",
    "AllTab = AllTab.T\n",
    "AllTab['plsig_c'] = AllTab['lsig_c']/AllTab['lsig_y2']\n",
    "AllTab = AllTab[final_names]\n",
    "\n",
    "AllTab['N'] = np.array(noobs)\n",
    "\n",
    "#columns\n",
    "AllTab = AllTab.T\n",
    "AllTab = AllTab[['Raw','LTU','STU+SpellAdj','NE+SpellAdj']]\n",
    "AllTab = AllTab.rename(columns={'STU+SpellAdj':'STU','NE+SpellAdj':\"NE\"})\n",
    "for name in final_names:\n",
    "    if name in parenthesis_names:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"({:,.2f})\".format(float(x)))\n",
    "    else:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"{:,.2f}\".format(float(x)))\n",
    "AllTab.loc['n'] = AllTab.loc['N'].apply(lambda x: \"{:,.0f}\".format(float(x)))\n",
    "\n",
    "AllTab = AllTab.rename(index=dict(zip(names,names_latex)))\n",
    "print(AllTab.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} &       Women &         Men &     College & Non-College \\\\\n",
      "\\midrule\n",
      "$\\hat{\\mu}_y$    &      283.31 &      177.77 &      196.67 &      230.11 \\\\\n",
      "$\\hat{\\sigma}_y$ &  247,415.30 &  103,309.30 &  125,476.80 &  178,642.70 \\\\\n",
      "$\\hat{\\sigma}_c$ &  104,577.40 &   44,241.58 &   52,229.30 &   74,776.85 \\\\\n",
      "                 &      (0.42) &      (0.43) &      (0.42) &      (0.42) \\\\\n",
      "$\\hat{\\sigma}_e$ &  118,522.90 &   46,428.03 &   59,697.75 &   82,038.80 \\\\\n",
      "                 &      (0.48) &      (0.45) &      (0.48) &      (0.46) \\\\\n",
      "$\\hat{\\sigma}_b$ &   24,314.96 &   12,639.70 &   13,549.70 &   21,827.08 \\\\\n",
      "                 &      (0.10) &      (0.12) &      (0.11) &      (0.12) \\\\\n",
      "$\\hat{\\sigma}_c$ &        1.64 &        1.64 &        1.64 &        1.64 \\\\\n",
      "                 &      (0.55) &      (0.58) &      (0.55) &      (0.56) \\\\\n",
      "$\\hat{\\sigma}_e$ &        0.87 &        0.69 &        0.87 &        0.74 \\\\\n",
      "                 &      (0.28) &      (0.24) &      (0.28) &      (0.24) \\\\\n",
      "$\\hat{\\sigma}_b$ &        0.45 &        0.49 &        0.46 &        0.53 \\\\\n",
      "                 &      (0.16) &      (0.18) &      (0.16) &      (0.19) \\\\\n",
      "N                &     302,246 &     370,210 &     120,226 &     571,454 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_raw_e, names, column_names_e, noobs_e = read_results('results/all_results_educ_96.log')\n",
    "table_raw_g, names, column_names_g, noobs_g = read_results('results/all_results_sex_96.log')\n",
    "names_latex = format_names(names)\n",
    "final_names = ['mu_y','sig_y','sig_c','psig_c','sig_e','psig_e','sig_b','psig_b',\n",
    "                     'lsig_c','plsig_c','lsig_e','lpsig_e','lsig_b','lpsig_b']\n",
    "parenthesis_names = ['psig_c','psig_e','psig_b','plsig_c','lpsig_e','lpsig_b']\n",
    "# table_raw_r, names_r, column_names_r, noobs_r = read_results('results/table_recalls.log')\n",
    "names[6] = 'lsig_co'\n",
    "AllTab = pd.DataFrame(table_raw_g[1:,:].T, index=names, columns=column_names_g)\n",
    "Tab_e = pd.DataFrame(table_raw_e[1:,:].T, index=names, columns=column_names_e)\n",
    "AllTab= pd.concat((AllTab,Tab_e),axis=1)\n",
    "\n",
    "# rows\n",
    "AllTab = AllTab.T\n",
    "AllTab['plsig_c'] = AllTab['lsig_c']/AllTab['lsig_y2']\n",
    "AllTab = AllTab[final_names]\n",
    "\n",
    "AllTab['N'] = np.array(np.hstack((noobs_g,noobs_e)))\n",
    "\n",
    "#columns\n",
    "AllTab = AllTab.T\n",
    "# \n",
    "AllTab = AllTab.rename(columns={'STU+SpellAdj,women':'Women','STU+SpellAdj,men':'Men',\n",
    "                               'STU+SpellAdj,college':'College','STU+SpellAdj,nocollege':'Non-College'})\n",
    "AllTab = AllTab[['Women','Men','College','Non-College']]\n",
    "for name in final_names:\n",
    "    if name in parenthesis_names:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"({:,.2f})\".format(float(x)))\n",
    "    else:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"{:,.2f}\".format(float(x)))\n",
    "AllTab.loc['N'] = AllTab.loc['N'].apply(lambda x: \"{:,.0f}\".format(float(x)))\n",
    "\n",
    "AllTab = AllTab.rename(index=dict(zip(names,names_latex)))\n",
    "print(AllTab.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "{} &  2002-2007 &  2008-2013 \\\\\n",
      "\\midrule\n",
      "$\\hat{\\mu}_y$    &     164.80 &     201.55 \\\\\n",
      "$\\hat{\\sigma}_y$ &  88,063.33 &  77,577.36 \\\\\n",
      "$\\hat{\\sigma}_c$ &  39,413.73 &  45,366.67 \\\\\n",
      "                 &     (0.45) &     (0.58) \\\\\n",
      "$\\hat{\\sigma}_e$ &  36,393.47 &  27,466.68 \\\\\n",
      "                 &     (0.41) &     (0.35) \\\\\n",
      "$\\hat{\\sigma}_b$ &  12,256.13 &   4,744.01 \\\\\n",
      "                 &     (0.14) &     (0.06) \\\\\n",
      "$\\hat{\\sigma}_c$ &       1.64 &       1.64 \\\\\n",
      "                 &     (0.60) &     (0.70) \\\\\n",
      "$\\hat{\\sigma}_e$ &       0.57 &       0.44 \\\\\n",
      "                 &     (0.18) &     (0.17) \\\\\n",
      "$\\hat{\\sigma}_b$ &       0.54 &       0.28 \\\\\n",
      "                 &     (0.21) &     (0.13) \\\\\n",
      "N                &    301,482 &    332,684 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_raw_bc, names, column_names_bc, noobs_bc = read_results('results/BC_all.log')\n",
    "names_latex = format_names(names)\n",
    "final_names = ['mu_y','sig_y','sig_c','psig_c','sig_e','psig_e','sig_b','psig_b',\n",
    "                     'lsig_c','plsig_c','lsig_e','lpsig_e','lsig_b','lpsig_b']\n",
    "parenthesis_names = ['psig_c','psig_e','psig_b','plsig_c','lpsig_e','lpsig_b']\n",
    "names[6] = 'lsig_co'\n",
    "AllTab = pd.DataFrame(table_raw_bc[1:,:].T, index=names, columns=column_names_bc)\n",
    "\n",
    "# rows\n",
    "AllTab = AllTab.T\n",
    "AllTab['plsig_c'] = AllTab['lsig_c']/AllTab['lsig_y2']\n",
    "AllTab = AllTab[final_names]\n",
    "\n",
    "AllTab['N'] = np.array(noobs_bc)\n",
    "\n",
    "#columns\n",
    "AllTab = AllTab.T\n",
    "# \n",
    "AllTab = AllTab.rename(columns={'STU+Spellcorrection,2002-2007':'2002-2007',\n",
    "                               'STU+Spellcorrection,2008-2013':'2008-2013'})\n",
    "\n",
    "for name in final_names:\n",
    "    if name in parenthesis_names:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"({:,.2f})\".format(float(x)))\n",
    "    else:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"{:,.2f}\".format(float(x)))\n",
    "AllTab.loc['N'] = AllTab.loc['N'].apply(lambda x: \"{:,.0f}\".format(float(x)))\n",
    "\n",
    "AllTab = AllTab.rename(index=dict(zip(names,names_latex)))\n",
    "print(AllTab.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} &  2002-2007 &  2008-2013 &  2002-2007 &  2008-2013 \\\\\n",
      "\\midrule\n",
      "$\\hat{\\mu}_y$    &     166.41 &     205.75 &     154.19 &     178.10 \\\\\n",
      "$\\hat{\\sigma}_y$ &  90,737.88 &  80,664.35 &  76,678.80 &  57,250.49 \\\\\n",
      "$\\hat{\\sigma}_c$ &  40,643.58 &  47,121.37 &  32,543.23 &  35,728.13 \\\\\n",
      "                 &     (0.45) &     (0.58) &     (0.42) &     (0.62) \\\\\n",
      "$\\hat{\\sigma}_e$ &  37,141.29 &  28,752.39 &  35,366.53 &  17,512.56 \\\\\n",
      "                 &     (0.41) &     (0.36) &     (0.46) &     (0.31) \\\\\n",
      "$\\hat{\\sigma}_b$ &  12,953.00 &   4,790.59 &   8,769.03 &   4,009.80 \\\\\n",
      "                 &     (0.14) &     (0.06) &     (0.11) &     (0.07) \\\\\n",
      "$\\hat{\\sigma}_c$ &       1.64 &       1.64 &       1.64 &       1.64 \\\\\n",
      "                 &     (0.60) &     (0.70) &     (0.58) &     (0.67) \\\\\n",
      "$\\hat{\\sigma}_e$ &       0.53 &       0.42 &       0.71 &       0.50 \\\\\n",
      "                 &     (0.17) &     (0.16) &     (0.23) &     (0.19) \\\\\n",
      "$\\hat{\\sigma}_b$ &       0.56 &       0.27 &       0.47 &       0.31 \\\\\n",
      "                 &     (0.22) &     (0.13) &     (0.18) &     (0.13) \\\\\n",
      "N                &    258,384 &    288,454 &     51,442 &     56,274 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_raw_bc, names, column_names_bc, noobs_bc = read_results('results/BC_educ.log')\n",
    "names_latex = format_names(names)\n",
    "final_names = ['mu_y','sig_y','sig_c','psig_c','sig_e','psig_e','sig_b','psig_b',\n",
    "                     'lsig_c','plsig_c','lsig_e','lpsig_e','lsig_b','lpsig_b']\n",
    "parenthesis_names = ['psig_c','psig_e','psig_b','plsig_c','lpsig_e','lpsig_b']\n",
    "names[6] = 'lsig_co'\n",
    "AllTab = pd.DataFrame(table_raw_bc[1:,:].T, index=names, columns=column_names_bc)\n",
    "\n",
    "# rows\n",
    "AllTab = AllTab.T\n",
    "AllTab['plsig_c'] = AllTab['lsig_c']/AllTab['lsig_y2']\n",
    "AllTab = AllTab[final_names]\n",
    "\n",
    "AllTab['N'] = np.array(noobs_bc)\n",
    "\n",
    "#columns\n",
    "AllTab = AllTab.T\n",
    "AllTab = AllTab[['STU+Spellcorrection,2002-2007,nocollege',\n",
    "               'STU+Spellcorrection,2008-2013,nocollege',\n",
    "               'STU+Spellcorrection,2002-2007,college',\n",
    "               'STU+Spellcorrection,2008-2013,college']]\n",
    "\n",
    "AllTab = AllTab.rename(columns={'STU+Spellcorrection,2002-2007,college':'2002-2007',\n",
    "                                'STU+Spellcorrection,2002-2007,nocollege':'2002-2007',\n",
    "                               'STU+Spellcorrection,2008-2013,college':'2008-2013',\n",
    "                                'STU+Spellcorrection,2008-2013,nocollege':'2008-2013'})\n",
    "\n",
    "for name in final_names:\n",
    "    if name in parenthesis_names:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"({:,.2f})\".format(float(x)))\n",
    "    else:\n",
    "        AllTab.loc[name]= AllTab.loc[name].apply(lambda x: \"{:,.2f}\".format(float(x)))\n",
    "AllTab.loc['N'] = AllTab.loc['N'].apply(lambda x: \"{:,.0f}\".format(float(x)))\n",
    "\n",
    "AllTab = AllTab.rename(index=dict(zip(names,names_latex)))\n",
    "print(AllTab.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
